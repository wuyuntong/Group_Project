---
title: "COVID-19 cases and deaths analysis"
format: html
editor: visual
author: Yuntong Wu & Jiaxin Shen
execute: 
  keep-md: true
---

## Research question

The COVID-19 crisis has wreaked havoc on the world economy and people's lives. In US, the impact has been staggering, with nearly 100 million people contracting the virus and over 1 million died of it as of mid-July, as reported by USAfacts. From cities to rural towns, it is important for policymakers to stay informed how COVID-19 is spreading and affects families, commerce, and travel to take measures. Our focus on this project is on scrutinizing COVID-19 data at the county level in the US from July 2020 to June 2021---a period marked by the peak severity of the pandemic and the coexistence of various policies. With the project, we aim to gain an understanding of how different factors and policies played a role during the pandemic.

First, our focus revolves around understanding the dynamics of the pandemic's progression within the US. It is crucial to delve into the data and find out whether there are tangible variations in the trends at some critical moments. For instance, we want to detect if there is a structural shift in the data following the implementation of policies to contain the spread of the virus. Also, we want to see if there is a dramatic increase in the confirmed cases or deaths during the outbreak of a new virus variant and how these numbers change as time goes by.

Furthermore, recognizing that states are different in various manners, our analysis seeks to uncover patterns of COVID cases and deaths that may be influenced by these differences. Our investigation extends to labeling the counties using the available characteristics. This could be done by using clustering techniques, such that counties with similar characteristics could be categorized into a group and others with disparate characteristics could be categorized into separate groups.

Lastly, this project also incorporates a nationwide exploration of the covariates that may have impacted the transmission of the virus. The recent study by Almalki et al. (2022) analyzed the cases and death numbers in Guilford County and found that food access and health issues are correlated with COVID cases and deaths by 0.44% and 60%, respectively. In a similar fashion, we consider a larger pool of factors including unemployment, poverty rate, income level, insurance coverage, alcohol abuse, heavy smoking, etc. By delving into these factors, we want to find out the influences that contribute to the number of deaths and infected cases on a broader scale. The intended approach for use is leveraging the linear regression model, and we will evaluate how the model works with its forecasting accuracy.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,message=FALSE, warning = FALSE)
```

```{r, echo=FALSE, message= FALSE}
here::i_am("Group_Project.Rproj")
library(here)
library(vroom)
library(dplyr)
library(tidyr)
library(ggplot2)
library(knitr)
library(caret)
library(tibble)
library(rpart)
library(rpart.plot)
library(cowplot)
library(stringr)
library(factoextra)
library(hopkins)
library(forecast)
library(lubridate)
library(tseries)
library(moments)
set.seed(123)
theme_set(theme_bw())
```

```{r, echo=FALSE, message=FALSE}
health <- vroom(here("data", "analytic_data2021.csv"))
cases <- vroom(here("data", "covid_confirmed_usafacts.csv"))
deaths <- vroom(here("data", "covid_deaths_usafacts.csv"))
edu <- vroom(here("data", "Education.csv"))
pop <- vroom(here("data", "PopulationEstimates.csv"))
pov <- vroom(here("data", "PovertyEstimates.csv"))
ump <- vroom(here("data", "Unemployment.csv"))
```

## Data sets description

To get reliable results, we first identify the data we need and determine where to get accurate and comprehensive data. The most basic information we need is the daily cumulative number of cases and deaths in different regions, which are the target variables of our research. Additionally, health data are essential. Finally, social-economic data may also play a crucial role. For example, higher income levels may lead to more timely treatment after infection, thereby reducing mortality. Higher education levels may help prevent and control the epidemic, thereby slowing down the growth rate of the number of cases. When selecting data sources, we strive to choose official, comprehensive sources to ensure the authenticity and accuracy of the data. Below are the descriptions of the data sources and variables.

### Description of data sources

1.Health data: The file analytic_data2021 comes from the County Health Rankings & Roadmaps (CHR&R). County Health Rankings & Roadmaps (CHR&R) is a program of the University of Wisconsin Population Health Institute. The CHR&R program provides data, evidence, guidance, and examples to build awareness of the multiple factors that influence health and support leaders in growing community power to improve health equity.

This file provides various health-related indicators for U.S. counties in 2021, including health behaviors, clinical care, as well as social and economic factors. Our focus is on six specific variables---Adult smoking, Adult obesity, Food environment index, Physical inactivity, Excessive drinking, Uninsured. We aim to investigate the correlation between these health metrics and COVID-19 numbers, seeking insights into the interplay between various factors and the pandemic's impact on communities.

2.COVID data: The files covid_confirmed_usafacts and covid_deaths_usafacts come from USAFacts. USAFacts currently counts presumptive positive cases as confirmed cases, as this is in line with how the CDC reports data. For deaths, USAFacts only takes those from state and local agencies if the virus played a direct role in causing death.

These two files provide daily cumulative data on confirmed cases and deaths attributed to the pandemic, organized by county in the United States spanning from January 2020 to July 2023. Notably, there are some cases counted at the state level are not allocated to counties due to lack of information. We select the number at the end of each month as monthly data to make it more intuitive and representative. The COVID confirmed cases number and COVID death number are the target variables of our analysis.

3.Social-economic data: These four files Education, PopulationEstimates, PovertyEstimates and Unemployment come from USDA's & Economic Research Service, which anticipate trends and emerging issues in agriculture, food, the environment, and rural America and to conduct high-quality, objective economic research to inform and enhance public and private decision making.

The Education dataset comes from multiple programs, including US Census Bureau and American Community Service. This file provides the basic information on the educational attainment of counties in the United States from 2017 to 2021. We focus on the variable, number of people having bachelor's degree or above, in this dataset.

PopulationEstimates are from U.S. Census Bureau for 1990, 2000, 2010, and 2020 Censuses of Population, and and Population Estimates Program (PEP). We select population and total deaths for analysis.

PovertyEstimates are model-based estimates from the U.S. Census Bureau's Small Area Income and Poverty Estimate (SAIPE) program. For counties and states, the program models income and poverty estimates by combining survey data with population estimates and administrative records. The data file file includes the estimated statistics of counties in the United States in 2021. The number of people of all ages in poverty 2021 and median income are selected for analysis.

The county and State unemployment rates are from the Bureau of Labor Statistics (BLS) Local Area Unemployment Statistics (LAUS) program. The Local Area Unemployment Statistics (LAUS) program is a federal-state cooperative effort in which monthly estimates of total employment and unemployment are prepared for over 7,600 areas. This file includes overall employment status by county in the United States from 2000 to 2022. Median household is from the U.S. Census Bureau's Small Area Income and Poverty Estimate (SAIPE) program as in the previous dataset. The number of unemployed for each county is selected for this study.

### Basic information about the data files

```{r, echo=FALSE}
info <- function(df) {
  data.frame(file_name = deparse(substitute(df)), row_number = nrow(df), col_number = ncol(df), missing_number = sum(is.na(df))) |> knitr::kable()
}
```

```{r, echo=FALSE}
info(health)
```

```{r, echo=FALSE}
info(cases)
```

```{r, echo=FALSE}
info(deaths)
```

```{r, echo=FALSE}
info(edu)
```

```{r, echo=FALSE}
info(pop)
```

```{r, echo=FALSE}
info(pov)
```

```{r, echo=FALSE}
info(ump)
```

### Description of variables

Below is the description of variables that are used in the project after modification. For other variables, we refer interested readers to the data sources.

countyFIPS: Federal Information Processing Standard (FIPS) Code.

State: State abbreviation.

County Name: county names.

cases_mon: containing cumulative COVID-19 confirmed cases number at the end of each month from July 2020 to June 2021.

deaths_mon: containing cumulative COVID-19 death number at the end of each month from July 2020 to June 2021.

Smoke: Percentage of adults who are current smokers (age-adjusted).

Obesity: Percentage of the adult population (age 20 and older) that reports a body mass index (BMI) greater than or equal to 30 kg/m2.

Food environment index: Index of factors that contribute to a healthy food environment, from 0 (worst) to 10 (best).

Physical inactivity: Percentage of adults age 20 and over reporting no leisure-time physical activity.

Drinking: Percentage of adults reporting binge or heavy drinking (age-adjusted).

Uninsured: Percentage of population under age 65 without health insurance.

Homicide: Number of deaths due to homicide per 100,000 population.

Rural: Percentage of population living in a rural area.

Below 18: Percentage of population below 18 years of age.

Above 65: Percentage of population ages 65 and older.

Poverty: Percentage of estimated number of people of all ages in poverty 2021.

Unemployed: Percentage of unemployment in 2021.

Population: 4/1/2020 resident Census 2020 population.

Median Income: Estimate of median household income in 2021.

Total Deaths: Percentage of death number in period 7/1/2020 to 6/30/2021.

Higher Education: Percentage of adults with a bachelor's degree or higher, 2017-21.

## Data analysis

After obtaining reliable data, we analyze the data from several aspects. Firstly, we present the overall graphical representations of the data, qualitatively discussing the trends in cumulative cases and deaths. As well as new cases and new deaths. Secondly, we conduct time series analysis on the national total cases and deaths, examining whether there are temporal correlations. We fit an ARIMA model to quantitatively analyze the trend of data over time. Subsequently, we employ the K-means clustering analysis method to cluster different countries. Finally, we use the regression tree method to analyze the impact of various variables on the death rate.

```{r, echo=FALSE}
cov_clean <- function(df) {
  df$countyFIPS <- df$countyFIPS |>
    as.character() |>
    str_pad(5, pad = "0")
  
  df$countyFIPS <- ifelse(df$`County Name` == "Statewide Unallocated", "99999", df$countyFIPS)
  
  df <- df |>
    select(
      countyFIPS, `County Name`, State, StateFIPS,
      `2020-07-31`, `2020-08-31`, `2020-09-30`, `2020-10-31`,
      `2020-11-30`, `2020-12-31`, `2021-01-31`, `2021-02-28`,
      `2021-03-31`, `2021-04-30`, `2021-05-31`, `2021-06-30`
    ) |>
    rename(
      `2020-07` = `2020-07-31`,
      `2020-08` = `2020-08-31`,
      `2020-09` = `2020-09-30`,
      `2020-10` = `2020-10-31`,
      `2020-11` = `2020-11-30`,
      `2020-12` = `2020-12-31`,
      `2021-01` = `2021-01-31`,
      `2021-02` = `2021-02-28`,
      `2021-03` = `2021-03-31`,
      `2021-04` = `2021-04-30`,
      `2021-05` = `2021-05-31`,
      `2021-06` = `2021-06-30`
    )
  
  US <- data.frame(
    countyFIPS = "00000",
    `County Name` = "United States",
    State = NA,
    StateFIPS = NA,
    `2020-07` = NA,
    `2020-08` = NA,
    `2020-09` = NA,
    `2020-10` = NA,
    `2020-11` = NA,
    `2020-12` = NA,
    `2021-01` = NA,
    `2021-02` = NA,
    `2021-03` = NA,
    `2021-04` = NA,
    `2021-05` = NA,
    `2021-06` = NA,
    check.names = FALSE
  )
  
  df <- bind_rows(US, df)
}
```

```{r, echo=FALSE}
cases_mon <- cov_clean(cases)
deaths_mon <- cov_clean(deaths)
```

```{r, echo=FALSE}
edu_c <- edu |>
  select(`Federal Information Processing Standard (FIPS) Code`, `Bachelor's degree or higher, 2017-21`) |>
  rename(
    countyFIPS = `Federal Information Processing Standard (FIPS) Code`,
    `Higher Education` = `Bachelor's degree or higher, 2017-21`
  )
```

```{r, echo=FALSE}
pop_c <- pop |>
  select(FIPStxt, CENSUS_2020_POP, DEATHS_2021) |>
  rename(
    countyFIPS = FIPStxt,
    Population = CENSUS_2020_POP,
    `Total Deaths` = DEATHS_2021
  )
```

```{r, echo=FALSE}
pov_c <- pov |>
  select(FIPS_Code, POVALL_2021, MEDHHINC_2021) |>
  rename(
    countyFIPS = FIPS_Code,
    Poverty = POVALL_2021,
    `Median Income` = MEDHHINC_2021
  )
```

```{r, echo=FALSE}
ump_c <- ump |>
  select(FIPS_Code, Unemployed_2021) |>
  rename(
    countyFIPS = FIPS_Code,
    Unemployed = Unemployed_2021
  )
```

```{r, echo=FALSE}
health_c <- health[2:nrow(health), ] |>
  mutate(countyFIPS = paste(`State FIPS Code`, `County FIPS Code`, sep = "")) |>
  select(countyFIPS, `Adult smoking raw value`, `Adult obesity raw value`, `Food environment index raw value`, `Physical inactivity raw value`, `Excessive drinking raw value`, `Uninsured raw value`, `Homicides raw value`, `% Rural raw value`, `% below 18 years of age raw value`, `% 65 and older raw value`) |>
  rename(
    Smoke = `Adult smoking raw value`,
    Obesity = `Adult obesity raw value`,
    `Food Environment` = `Food environment index raw value`,
    `Physical inactivity` = `Physical inactivity raw value`,
    Drinking = `Excessive drinking raw value`,
    Uninsured = `Uninsured raw value`,
    Homicide = `Homicides raw value`,
    Rural = `% Rural raw value`,
    `Below 18` = `% below 18 years of age raw value`,
    `Above 65` = `% 65 and older raw value`
  ) |>
  mutate(
    Smoke = as.numeric(Smoke),
    Obesity = as.numeric(Obesity),
    `Food Environment` = as.numeric(`Food Environment`),
    `Physical inactivity` = as.numeric(`Physical inactivity`),
    Drinking = as.numeric(Drinking),
    Uninsured = as.numeric(Uninsured),
    Homicide = as.numeric(Homicide),
    Rural = as.numeric(Rural),
    `Below 18` = as.numeric(`Below 18`),
    `Above 65` = as.numeric(`Above 65`)
  )
```

```{r, echo=FALSE}
cases_f <- cases_mon |>
  left_join(health_c, by = "countyFIPS") |>
  left_join(edu_c, by = "countyFIPS") |>
  left_join(pop_c, by = "countyFIPS") |>
  left_join(pov_c, by = "countyFIPS") |>
  left_join(ump_c, by = "countyFIPS") |>
  na.omit()

cases_f$`Higher Education` <- cases_f$`Higher Education` / cases_f$Population
cases_f$`Total Deaths` <- cases_f$`Total Deaths` / cases_f$Population
cases_f$Poverty <- cases_f$Poverty / cases_f$Population
cases_f$Unemployed <- cases_f$Unemployed / cases_f$Population


deaths_f <- deaths_mon |>
  left_join(health_c, by = "countyFIPS") |>
  left_join(edu_c, by = "countyFIPS") |>
  left_join(pop_c, by = "countyFIPS") |>
  left_join(pov_c, by = "countyFIPS") |>
  left_join(ump_c, by = "countyFIPS") |>
  na.omit()

deaths_f$`Higher Education` <- deaths_f$`Higher Education` / deaths_f$Population
deaths_f$`Total Deaths` <- deaths_f$`Total Deaths` / deaths_f$Population
deaths_f$Poverty <- deaths_f$Poverty / deaths_f$Population
deaths_f$Unemployed <- deaths_f$Unemployed / deaths_f$Population
```

### Graphic representation of target variables

```{r, echo=FALSE, warning=FALSE}
cases_mon |>
  group_by(State) |>
  summarise(across(starts_with("202"), sum, na.rm = TRUE)) |>
  pivot_longer(cols = starts_with("202"), names_to = "month", values_to = "count") |>
  ggplot(aes(x = month, y = count, group = State, color = State)) +
  geom_line() +
  labs(title = "Total cases reported across all 50 states from July 2020 to June 2021") +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(margin = margin(b = 40))
  )
```

```{r, echo=FALSE}
deaths_mon |>
  group_by(State) |>
  summarise(across(starts_with("202"), sum, na.rm = TRUE)) |>
  pivot_longer(cols = starts_with("202"), names_to = "month", values_to = "count") |>
  ggplot(aes(x = month, y = count, group = State, color = State)) +
  geom_line() +
  labs(title = "Total deaths reported across all 50 states from July 2020 to June 2021") +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(margin = margin(b = 40))
  )
```

```{r, echo=FALSE}
cases_mon |>
  group_by(State) |>
  summarise(across(starts_with("202"), sum, na.rm = TRUE)) |>
  pivot_longer(cols = starts_with("202"), names_to = "month", values_to = "count") |>
  group_by(State) |>
  mutate_at(vars(count), list(~ .x - lag(.x))) |>
  na.omit() |>
  ggplot(aes(x = month, y = count, group = State, color = State)) +
  geom_line() +
  labs(title = "New cases reported across all 50 states from August 2020 to June 2021") +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(margin = margin(b = 40))
  )
```

```{r, echo=FALSE}
deaths_mon |>
  group_by(State) |>
  summarise(across(starts_with("202"), sum, na.rm = TRUE)) |>
  pivot_longer(cols = starts_with("202"), names_to = "month", values_to = "count") |>
  group_by(State) |>
  mutate_at(vars(count), list(~ .x - lag(.x))) |>
  na.omit() |>
  ggplot(aes(x = month, y = count, group = State, color = State)) +
  geom_line() +
  labs(title = "New deaths reported across all 50 states from August 2020 to June 2021") +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(margin = margin(b = 40))
  )
```

```{r, echo=FALSE}
cases_mon |>
  summarise(across(starts_with("202"), sum, na.rm = TRUE)) |>
  pivot_longer(cols = starts_with("202"), names_to = "month", values_to = "count") |>
  ggplot(aes(x = month, y = count, group = 1)) +
  geom_line() +
  labs(title = "Nationwide total cases reported from July 2020 to June 2021")
```

```{r, echo=FALSE}
deaths_mon |>
  summarise(across(starts_with("202"), sum, na.rm = TRUE)) |>
  pivot_longer(cols = starts_with("202"), names_to = "month", values_to = "count") |>
  ggplot(aes(x = month, y = count, group = 1)) +
  geom_line() +
  labs(title = "Nationwide total deaths reported from July 2020 to June 2021")
```

```{r, echo=FALSE}
cases_mon |>
  summarise(across(starts_with("202"), sum, na.rm = TRUE)) |>
  pivot_longer(cols = starts_with("202"), names_to = "month", values_to = "count") |>
  mutate_at(vars(count), list(~ .x - lag(.x))) |>
  na.omit() |>
  ggplot(aes(x = month, y = count, group = 1)) +
  geom_line() +
  labs(title = "Nationwide new cases reported from August 2020 to June 2021")
```

```{r, echo=FALSE}
deaths_mon |>
  summarise(across(starts_with("202"), sum, na.rm = TRUE)) |>
  pivot_longer(cols = starts_with("202"), names_to = "month", values_to = "count") |>
  mutate_at(vars(count), list(~ .x - lag(.x))) |>
  na.omit() |>
  ggplot(aes(x = month, y = count, group = 1)) +
  geom_line() +
  labs(title = "Nationwide new deaths reported from August 2020 to June 2021")
```

### Variables distribution

Observing the variables, we found that they are all continuos variables. Thus in this section, we will use national county-level data to graphically display and describe the distribution of variables in terms of frequency distribution, density curves, and indicators such as mean, variance, skewness and kurtosis.

#### Smoking rate

```{r}
ggplot(data = health_c, aes(x = Smoke)) +
  geom_histogram(color = "black",bins = 50)  +
  labs(title = "Distribution of smoking rate", x = "Smoking rate", y = "Frequency")
ggplot(data = health_c, aes(x = Smoke)) +
 geom_density()+
  geom_vline(aes(xintercept = mean(Smoke,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5)+  
  geom_vline(aes(xintercept = median(Smoke,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5,color="red") +
  geom_vline(aes(xintercept = quantile(Smoke, 0.25,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5) +
  geom_vline(aes(xintercept = quantile(Smoke, 0.75,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5) +
  geom_text(aes(x = mean(Smoke,na.rm = TRUE), y = 0.25, label = "Mean"), vjust = -25) +
  geom_text(aes(x = median(Smoke,na.rm = TRUE), y = 0.25,label = "Median",color="red"), vjust = -24,hjust=-0.3) +
  geom_text(aes(x = quantile(Smoke, 0.25,na.rm = TRUE), y = 0.25, label = "25%"), vjust = -1) +
  geom_text(aes(x = quantile(Smoke, 0.75,na.rm = TRUE), y = 0.25, label = "75%"), vjust = -1)+
  labs(title = "Density Curve", x = "Smoking rate",y="Density")
health_c |>
  summarise(missing_count=sum(is.na(Smoke)),
            max=max(Smoke,na.rm = TRUE),
            min=min(Smoke,na.rm = TRUE),
    mean = mean(Smoke,na.rm = TRUE),
    median = median(Smoke,na.rm = TRUE),
    variance = var(Smoke,na.rm = TRUE),
    skewness = skewness(Smoke,na.rm = TRUE),
    kurtosis = kurtosis(Smoke,na.rm = TRUE)) |>
  knitr::kable(digits = 3)
```

Based on these metrics, we can make the following observations and inferences: Range:The maximum value is 0.403, and the minimum value is 0.071.

Central Tendency: The mean and median are very close, indicating that the central position of the dataset is around these two values.

Dispersion: A small variance value (0.002) suggests that the data is relatively concentrated, with low dispersion.

Skewness: A positive skewness value (0.218) indicates a slight right-skewed distribution, implying a slight positive skew.

Kurtosis: A high kurtosis value (3.641) indicates a sharper peak in the distribution compared to a normal distribution. This aslo suggests a strong concentration of data around the mean.

#### Obesity rate

```{r}
ggplot(data = health_c, aes(x = Obesity)) +
  geom_histogram(color = "black",bins = 50) +
  labs(title = "Distribution of obesity rate", x = "Obesity rate", y = "Frequency")
ggplot(data = health_c, aes(x =Obesity)) +
 geom_density()+
  geom_vline(aes(xintercept = mean(Obesity,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5)+
  geom_vline(aes(xintercept = median(Obesity,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5,color="red") +
  geom_vline(aes(xintercept = quantile(Obesity, 0.25,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5) +
  geom_vline(aes(xintercept = quantile(Obesity, 0.75,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5) +
  geom_text(aes(x = mean(Obesity,na.rm = TRUE), y = 0.25, label = "Mean"), vjust = -25) +
  geom_text(aes(x = median(Obesity,na.rm = TRUE), y = 0.25,label = "Median",color="red"), vjust = -24,hjust=-0.3) +
  geom_text(aes(x = quantile(Obesity, 0.25,na.rm = TRUE), y = 0.25, label = "25%"),vjust = -1) +
  geom_text(aes(x = quantile(Obesity, 0.75,na.rm = TRUE), y = 0.25, label = "75%"), vjust = -1)+
  labs(title = "Density Curve", x = "Obesity rate",y="Density")
health_c |>
  summarise(missing_count=sum(is.na(Obesity)),
            max=max(Obesity,na.rm = TRUE),
            min=min(Obesity,na.rm = TRUE),
    mean = mean(Obesity,na.rm = TRUE),
    median = median(Obesity,na.rm = TRUE),
    variance = var(Obesity,na.rm = TRUE),
    skewness = skewness(Obesity,na.rm = TRUE),
    kurtosis = kurtosis(Obesity,na.rm = TRUE)) |>
  knitr::kable(digits = 3)
```

Range:The maximum value is 0.589, and the minimum value is 0.143.

Central Tendency: The mean and median are very close, indicating that the central position of the dataset is around these two values.

Dispersion: The relatively small variance value (0.004) suggests that the data is relatively concentrated, with low dispersion.

Skewness: The skewness is a negative value (-0.069), indicating a slight leftward skew in the distribution. This suggests that there are relatively more smaller values in the dataset compared to larger values.

Kurtosis: The kurtosis value (3.41) is relatively high, indicating a sharper peak in the distribution compared to a normal distribution. This could imply that there are more outliers in the tails of the distribution or that the data is more concentrated around the mean.

#### Food environment

```{r}
ggplot(data = health_c, aes(x = `Food Environment`)) +
  geom_histogram(color = "black",bins = 50) +
  labs(title = "Distribution of Food Environment", x = "Food Environment", y = "Frequency")
ggplot(data = health_c, aes(x =`Food Environment`)) +
 geom_density()+
  geom_vline(aes(xintercept = mean(`Food Environment`,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5)+
  geom_vline(aes(xintercept = median(`Food Environment`,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5,color="red") +
  geom_vline(aes(xintercept = quantile(`Food Environment`, 0.25,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5) +
  geom_vline(aes(xintercept = quantile(`Food Environment`, 0.75,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5) +
  geom_text(aes(x = mean(`Food Environment`,na.rm = TRUE), y = 0.25, label = "Mean"), vjust = -5) +
  geom_text(aes(x = median(`Food Environment`,na.rm = TRUE), y = 0.25,label = "Median",color="red"), vjust = -5,hjust=-0.3) +
  geom_text(aes(x = quantile(`Food Environment`, 0.25,na.rm = TRUE), y = 0.25, label = "25%"),vjust = 5) +
  geom_text(aes(x = quantile(`Food Environment`, 0.75,na.rm = TRUE), y = 0.25, label = "75%"), vjust = 5)+
  labs(title = "Density Curve", x = "Food Environment",y="Density")
health_c |>
  summarise(missing_count=sum(is.na(`Food Environment`)),
            max=max(`Food Environment`,na.rm = TRUE),
            min=min(`Food Environment`,na.rm = TRUE),
    mean = mean(`Food Environment`,na.rm = TRUE),
    median = median(`Food Environment`,na.rm = TRUE),
    variance = var(`Food Environment`,na.rm = TRUE),
    skewness = skewness(`Food Environment`,na.rm = TRUE),
    kurtosis = kurtosis(`Food Environment`,na.rm = TRUE)) |>
  knitr::kable(digits = 3)
```

Range of Distribution: The minimum value is 0, and the maximum is 10.

Central Tendency: The mean and median are close, indicating that the overall trend of the data centres around 7.446.

Dispersion: The relatively large variance (1.329) suggests a dispersed distribution.

Skewness: The negative skewness (-1.316) indicates a slight leftward skew, suggesting a relatively higher frequency of smaller values.

Kurtosis: The high kurtosis value (6.74) implies a sharper peak compared to a normal distribution. This indicates a heavier tail in the distribution with some extreme values.

#### Physical inactivity

```{r}
ggplot(data = health_c, aes(x = `Physical inactivity`)) +
  geom_histogram(color = "black",bins = 50) +
  labs(title = "Distribution of Physical inactivity", x = "Physical inactivity", y = "Frequency")
ggplot(data = health_c, aes(x =`Physical inactivity`)) +
 geom_density()+
  geom_vline(aes(xintercept = mean(`Physical inactivity`,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5)+
  geom_vline(aes(xintercept = median(`Physical inactivity`,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5,color="red") +
  geom_vline(aes(xintercept = quantile(`Physical inactivity`, 0.25,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5) +
  geom_vline(aes(xintercept = quantile(`Physical inactivity`, 0.75,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5) +
  geom_text(aes(x = mean(`Physical inactivity`,na.rm = TRUE), y = 0.25, label = "Mean"), vjust = -5) +
  geom_text(aes(x = median(`Physical inactivity`,na.rm = TRUE), y = 0.25,label = "Median",color="red"), vjust = -4,hjust=-0.3) +
  geom_text(aes(x = quantile(`Physical inactivity`, 0.25,na.rm = TRUE), y = 0.25, label = "25%"),vjust = -5) +
  geom_text(aes(x = quantile(`Physical inactivity`, 0.75,na.rm = TRUE), y = 0.25, label = "75%"), vjust = -5)+
  labs(title = "Density Curve", x = "Physical inactivity",y="Density")
health_c |>
  summarise(missing_count=sum(is.na(`Physical inactivity`)),
            max=max(`Physical inactivity`,na.rm = TRUE),
            min=min(`Physical inactivity`,na.rm = TRUE),
    mean = mean(`Physical inactivity`,na.rm = TRUE),
    median = median(`Physical inactivity`,na.rm = TRUE),
    variance = var(`Physical inactivity`,na.rm = TRUE),
    skewness = skewness(`Physical inactivity`,na.rm = TRUE),
    kurtosis = kurtosis(`Physical inactivity`,na.rm = TRUE)) |>
  knitr::kable(digits = 3)
```

Range: The minimum value is 0.089, and the maximum is 0.504.

Central Tendency: The mean and median are close, indicating that the overall trend of the data centrers around 0.266.

Dispersion: The variance is relatively small (0.003), suggesting a concentrated distribution,with low dispersion.

Skewness: The positive skewness (0.181) indicates a slight rightward skew, suggesting a slightly higher frequency of larger values.

Kurtosis: The kurtosis value (2.98) implies a distribution peak that is sharper than a normal distribution. This may suggest a distribution with a moderate concentration around the mean.

#### Drinking rate

```{r}
ggplot(data = health_c, aes(x = `Drinking`)) +
  geom_histogram(color = "black",bins = 50) +
  labs(title = "Distribution of Drinking", x = "Drinking rate", y = "Frequency")
ggplot(data = health_c, aes(x =`Drinking`)) +
 geom_density()+
  geom_vline(aes(xintercept = mean(`Drinking`,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5)+
  geom_vline(aes(xintercept = median(`Drinking`,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5,color="red") +
  geom_vline(aes(xintercept = quantile(`Drinking`, 0.25,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5) +
  geom_vline(aes(xintercept = quantile(`Drinking`, 0.75,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5) +
  geom_text(aes(x = mean(`Drinking`,na.rm = TRUE), y = 0.25, label = "Mean"), vjust = -5) +
  geom_text(aes(x = median(`Drinking`,na.rm = TRUE), y = 0.25,label = "Median",color="red"), vjust = -4,hjust=-0.3) +
  geom_text(aes(x = quantile(`Drinking`, 0.25,na.rm = TRUE), y = 0.25, label = "25%"),vjust = -5) +
  geom_text(aes(x = quantile(`Drinking`, 0.75,na.rm = TRUE), y = 0.25, label = "75%"), vjust = -5)+
  labs(title = "Density Curve", x = "Drinking rate",y="Density")
health_c |>
  summarise(missing_count=sum(is.na(`Drinking`)),
            max=max(`Drinking`,na.rm = TRUE),
            min=min(`Drinking`,na.rm = TRUE),
    mean = mean(`Drinking`,na.rm = TRUE),
    median = median(`Drinking`,na.rm = TRUE),
    variance = var(`Drinking`,na.rm = TRUE),
    skewness = skewness(`Drinking`,na.rm = TRUE),
    kurtosis = kurtosis(`Drinking`,na.rm = TRUE)) |>
  knitr::kable(digits = 3)
```

Range: The minimum value is 0.065, and the maximum is 0.0.31.

Central Tendency: The mean and median are close, indicating that the overall trend of the data centrers around 0.191.

Dispersion: The variance is relatively small (0.001), suggesting a concentrated distribution,with low dispersion.

Skewness: The positive skewness (0.192) indicates a slight rightward skew, suggesting a slightly higher frequency of larger values.

Kurtosis: The kurtosis value (2.77) implies a distribution peak that is sharper than a normal distribution. This may suggest a distribution with a moderate concentration around the mean.

#### Uninsured rate

```{r}
ggplot(data = health_c, aes(x = `Uninsured`)) +
  geom_histogram(color = "black",bins = 50) +
  labs(title = "Distribution of Uninsured", x = "Uninsured rate", y = "Frequency")
ggplot(data = health_c, aes(x =`Uninsured`)) +
 geom_density()+
  geom_vline(aes(xintercept = mean(`Uninsured`,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5)+
  geom_vline(aes(xintercept = median(`Uninsured`,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5,color="red") +
  geom_vline(aes(xintercept = quantile(`Uninsured`, 0.25,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5) +
  geom_vline(aes(xintercept = quantile(`Uninsured`, 0.75,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5) +
  geom_text(aes(x = mean(`Uninsured`,na.rm = TRUE), y = 0.25, label = "Mean"), vjust = -5) +
  geom_text(aes(x = median(`Uninsured`,na.rm = TRUE), y = 0.25,label = "Median",color="red"), vjust = -4,hjust=-0.3) +
  geom_text(aes(x = quantile(`Uninsured`, 0.25,na.rm = TRUE), y = 0.25, label = "25%"),vjust = -1) +
  geom_text(aes(x = quantile(`Uninsured`, 0.75,na.rm = TRUE), y = 0.25, label = "75%"), vjust = -1)+
  labs(title = "Density Curve", x = "Uninsured rate",y="Density")
health_c |>
  summarise(missing_count=sum(is.na(`Uninsured`)),
            max=max(`Uninsured`,na.rm = TRUE),
            min=min(`Uninsured`,na.rm = TRUE),
    mean = mean(`Uninsured`,na.rm = TRUE),
    median = median(`Uninsured`,na.rm = TRUE),
    variance = var(`Uninsured`,na.rm = TRUE),
    skewness = skewness(`Uninsured`,na.rm = TRUE),
    kurtosis = kurtosis(`Uninsured`,na.rm = TRUE)) |>
  knitr::kable(digits = 3)
```

Range: The minimum value is 0.024, and the maximum is 0.322.

Central Tendency: The mean and median are relatively close, indicating that the overall trend of the data centers around 0.115.

Dispersion: The variance is relatively small, suggesting a concentrated distribution,with low dispersion.

Skewness: The positive skewness indicates a rightward skew, suggesting a slightly higher frequency of larger values.

Kurtosis: The kurtosis value implies a distribution peak that is sharper than a normal distribution. This suggests a distribution with a concentration around the mean and heavier tails.

#### Homicide

```{r}
ggplot(data = health_c, aes(x = `Homicide`)) +
  geom_histogram(color = "black",bins = 50) +
  labs(title = "Distribution of Homicide", x = "Homicide", y = "Frequency")
ggplot(data = health_c, aes(x =`Homicide`)) +
 geom_density()+
  geom_vline(aes(xintercept = mean(`Homicide`,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5)+
  geom_vline(aes(xintercept = median(`Homicide`,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5,color="red") +
  geom_vline(aes(xintercept = quantile(`Homicide`, 0.25,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5) +
  geom_vline(aes(xintercept = quantile(`Homicide`, 0.75,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5) +
  geom_text(aes(x = mean(`Homicide`,na.rm = TRUE), y = 0.25, label = "Mean"), vjust = 3) +
  geom_text(aes(x = median(`Homicide`,na.rm = TRUE), y = 0.25,label = "Median",color="red"), vjust = 4,hjust=0.3) +
  geom_text(aes(x = quantile(`Homicide`, 0.25,na.rm = TRUE), y = 0.25, label = "25%"),vjust = 15) +
  geom_text(aes(x = quantile(`Homicide`, 0.75,na.rm = TRUE), y = 0.25, label = "75%"), vjust = 15)+
  labs(title = "Density Curve", x = "Homicide",y="Density")
health_c |>
  summarise(missing_count=sum(is.na(`Homicide`)),
            max=max(`Homicide`,na.rm = TRUE),
            min=min(`Homicide`,na.rm = TRUE),
    mean = mean(`Homicide`,na.rm = TRUE),
    median = median(`Homicide`,na.rm = TRUE),
    variance = var(`Homicide`,na.rm = TRUE),
    skewness = skewness(`Homicide`,na.rm = TRUE),
    kurtosis = kurtosis(`Homicide`,na.rm = TRUE)) |>
  knitr::kable(digits = 3)
```

Range: The data has a wide range, from 0.0603 to 41.47,potentially including some extreme values.

Central Tendency: The mean and median are relatively close, but considering the right-skewed distribution, the median may better represent the central tendency of the data.

Dispersion: The variance is large, indicating that the data is relatively dispersed, possibly due to the presence of extreme values.

Skewness: Positive skewness indicates a right-skewed distribution, suggesting the presence of some relatively large values.

Kurtosis: High kurtosis indicates a distribution with a sharper peak and heavier tails, possibly indicating the presence of extreme values.

#### Rural rate

```{r}
ggplot(data = health_c, aes(x = `Rural`)) +
  geom_histogram(color = "black",bins = 50) +
  labs(title = "Distribution of Rural", x = "Rural", y = "Frequency")
ggplot(data = health_c, aes(x =`Rural`)) +
 geom_density()+
  geom_vline(aes(xintercept = mean(`Rural`,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5)+
  geom_vline(aes(xintercept = median(`Rural`,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5,color="red") +
  geom_vline(aes(xintercept = quantile(`Rural`, 0.25,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5) +
  geom_vline(aes(xintercept = quantile(`Rural`, 0.75,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5) +
  geom_text(aes(x = mean(`Rural`,na.rm = TRUE), y = 0.25, label = "Mean"), vjust = -5) +
  geom_text(aes(x = median(`Rural`,na.rm = TRUE), y = 0.25,label = "Median",color="red"), vjust = -5,hjust=-0.3) +
  geom_text(aes(x = quantile(`Rural`, 0.25,na.rm = TRUE), y = 0.25, label = "25%"),vjust = 5) +
  geom_text(aes(x = quantile(`Rural`, 0.75,na.rm = TRUE), y = 0.25, label = "75%"), vjust = 5)+
  labs(title = "Density Curve", x = "Rural",y="Density")
health_c |>
  summarise(missing_count=sum(is.na(`Rural`)),
            max=max(`Rural`,na.rm = TRUE),
            min=min(`Rural`,na.rm = TRUE),
    mean = mean(`Rural`,na.rm = TRUE),
    median = median(`Rural`,na.rm = TRUE),
    variance = var(`Rural`,na.rm = TRUE),
    skewness = skewness(`Rural`,na.rm = TRUE),
    kurtosis = kurtosis(`Rural`,na.rm = TRUE)) |>
  knitr::kable(digits = 3)
```

Range: The data ranges from 0 to 1.

Central Tendency: The mean and median are relatively close, indicating that the overall trend of the data centers around 0.58.

Dispersion: The variance is relatively small, suggesting a concentrated distribution,with low dispersion.

Skewness: Slight left-skewness suggests a tendency for smaller values.

Kurtosis: Moderate kurtosis indicates a distribution with a moderate peak and tails.

#### Below 18 rate

```{r}
ggplot(data = health_c, aes(x = `Below 18`)) +
  geom_histogram(color = "black",bins = 50) +
  labs(title = "Distribution of Below 18", x = "Below 18", y = "Frequency")
ggplot(data = health_c, aes(x =`Below 18`)) +
 geom_density()+
  geom_vline(aes(xintercept = mean(`Below 18`,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5)+
  geom_vline(aes(xintercept = median(`Below 18`,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5,color="red") +
  geom_vline(aes(xintercept = quantile(`Below 18`, 0.25,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5) +
  geom_vline(aes(xintercept = quantile(`Below 18`, 0.75,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5) +
  geom_text(aes(x = mean(`Below 18`,na.rm = TRUE), y = 0.25, label = "Mean"), vjust = -5) +
  geom_text(aes(x = median(`Below 18`,na.rm = TRUE), y = 0.25,label = "Median",color="red"), vjust = -5,hjust=-0.3) +
  geom_text(aes(x = quantile(`Below 18`, 0.25,na.rm = TRUE), y = 0.25, label = "25%"),vjust = -3) +
  geom_text(aes(x = quantile(`Below 18`, 0.75,na.rm = TRUE), y = 0.25, label = "75%"), vjust = -3)+
  labs(title = "Density Curve", x = "Below 18",y="Density")
health_c |>
  summarise(missing_count=sum(is.na(`Below 18`)),
            max=max(`Below 18`,na.rm = TRUE),
            min=min(`Below 18`,na.rm = TRUE),
    mean = mean(`Below 18`,na.rm = TRUE),
    median = median(`Below 18`,na.rm = TRUE),
    variance = var(`Below 18`,na.rm = TRUE),
    skewness = skewness(`Below 18`,na.rm = TRUE),
    kurtosis = kurtosis(`Below 18`,na.rm = TRUE)) |>
  knitr::kable(digits = 3)
```

Range: The data ranges from 0 to 0.417.

Central Tendency: The mean and median are relatively close, suggesting a symmetric or nearly symmetric distribution.

Dispersion: The extremely low variance indicates that the data points are very close to the mean.

Skewness: Positive skewness suggests a tendency for slightly larger values.

Kurtosis: High kurtosis indicates a distribution with a high peak and heavy tails.

#### Above 65 rate

```{r}
ggplot(data = health_c, aes(x = `Above 65`)) +
  geom_histogram(color = "black",bins = 50) +
  labs(title = "Distribution of Above 65", x = "Above 65", y = "Frequency")
ggplot(data = health_c, aes(x =`Above 65`)) +
 geom_density()+
  geom_vline(aes(xintercept = mean(`Above 65`,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5)+
  geom_vline(aes(xintercept = median(`Above 65`,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5,color="red") +
  geom_vline(aes(xintercept = quantile(`Above 65`, 0.25,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5) +
  geom_vline(aes(xintercept = quantile(`Above 65`, 0.75,na.rm = TRUE)), linetype = "dashed", linewidth = 0.5) +
  geom_text(aes(x = mean(`Above 65`,na.rm = TRUE), y = 0.25, label = "Mean"), vjust = -5) +
  geom_text(aes(x = median(`Above 65`,na.rm = TRUE), y = 0.25,label = "Median",color="red"), vjust = -5,hjust=-0.3) +
  geom_text(aes(x = quantile(`Above 65`, 0.25,na.rm = TRUE), y = 0.25, label = "25%"),vjust = 5) +
  geom_text(aes(x = quantile(`Above 65`, 0.75,na.rm = TRUE), y = 0.25, label = "75%"), vjust = 5)+
  labs(title = "Density Curve", x = "Above 65",y="Density")
health_c |>
  summarise(missing_count=sum(is.na(`Above 65`)),
            max=max(`Above 65`,na.rm = TRUE),
            min=min(`Above 65`,na.rm = TRUE),
    mean = mean(`Above 65`,na.rm = TRUE),
    median = median(`Above 65`,na.rm = TRUE),
    variance = var(`Above 65`,na.rm = TRUE),
    skewness = skewness(`Above 65`,na.rm = TRUE),
    kurtosis = kurtosis(`Above 65`,na.rm = TRUE)) |>
  knitr::kable(digits = 3)
```

Range: The data ranges from 0.049 to 0.582.

Central Tendency: The mean and median are relatively close, indicating that the overall trend of the data centers around 0.197.

Dispersion: The variance is relatively small, suggesting a concentrated distribution,with low dispersion.

Skewness: Positive skewness suggests a tendency for slightly larger values.

Kurtosis: High kurtosis indicates a distribution with a high peak and heavy tails.

### Time series analysis of national cases and deaths.

We aim to identify the specific trends in cases and deaths across various regions in the United States over a certain period. We have selected the daily cumulative data from July 31, 2020, to June 30, 2021. Initially, by plotting graphs and conducting an ADF test, we found that the original data was not stationary. After performing a second differencing, we obtained a relatively stable dataset.ARIMA model has the advantages of simplicity and the ability to handle non-stationary sequences. Consequently, we chose the ARIMA model as the foundational model for analysis. The initial 80% of the data is used as the training set, and the remaining 20% is utilized as the test set.

#### National cases

```{r}
national_cases <- cases |>
  select(starts_with("202"))|>
  summarise_all(sum, na.rm = TRUE)|>
  select(`2020-07-31`:`2021-06-30`) |>
  pivot_longer(everything(), names_to = "Date", values_to = "Cases")
```

```{r}
case_ts <- ts(national_cases$Cases)
plot.ts(case_ts,main = "Original data", xlab = "Cases", ylab = "Time")
plot.ts(diff(diff(case_ts)),main = "Second-order differenced data", ylab = "Second-order Differenced Cases", xlab = "Time")
adf.test(diff(diff(case_ts)))
```

The test statistic is -9.1682 with a lag order of 6, resulting in a p-value of 0.01.With a p-value less than the significance level (commonly 0.05),the alternative hypothesis of stationarity is supported for the second-order differenced series.

```{r}
train_case <- case_ts[1:270]
test_case <- case_ts[271:335] |>
  ts(start = '271') 
model_case <- auto.arima(train_case)
checkresiduals(model_case)
summary(model_case)
plot(forecast(model_case,h=65))
lines(test_case,lwd=2,col='red')
```

#### National deaths

```{r}
national_deaths <- deaths |>
  select(starts_with("202"))|>
  mutate(across(everything(), as.numeric))|>
  summarise_all(sum, na.rm = TRUE)|>  
  select(`2020-07-31`:`2021-06-30`) |>
  pivot_longer(everything(), names_to = "Date", values_to = "Deaths")
```

```{r}
death_ts <- ts(national_deaths$Deaths)
plot.ts(death_ts)
plot.ts(diff(diff(death_ts)))
```

```{r}
train_death <- death_ts[1:270]
test_death <- death_ts[271:335] |>
  ts(start = '271')
```

```{r}
model_death <- auto.arima(train_death)
checkresiduals(model_death)
summary(model_death)
plot(forecast(model_death,h=65))
lines(test_death,lwd=2,col='red')
```

#### Relationship between national cases and deaths

Besides examining the correlation between cases and deaths themselves, we also aim to determine if there is a significant relationship between cases and deaths. We opted for linear regression in this case. The results of the linear regression indicate a significant linear correlation between deaths and cases, implying that the virus's fatality rate is maybe a constant value, around 1.53%.

```{r}
national_data <- left_join(national_cases,national_deaths,'Date')
```

```{r}
c_relation <- lm(national_data$Deaths ~ national_data$Cases)
ggplot(national_data,aes(x = Cases, y = Deaths)) +
  geom_point(color = "blue") + 
  geom_abline(intercept = coef(c_relation)[1], slope = coef(c_relation)[2], color = "red") + 
  labs(x = "Cases", y = "Deats", title = "Linear Regression") +
  theme_minimal()
summary(c_relation)
```

### Clustering analysis

```{r, echo=FALSE}
df1 <- cases_f[, c("Higher Education", "Population", "Total Deaths", "Poverty", "Median Income", "Unemployed", "Homicide", "Rural", "Below 18", "Above 65")]
df <- as.data.frame(scale(df1))
hop <- hopkins(df)
```

We prepare our dataset for clustering analysis, which involves the extraction of all variables, excluding both the number of cases and identification variables for each county. The dataset is standardized to remove the effect of scales on the clustering. We evaluate the validity of clustering by assessing its clustering tendency because the most clustering methods are not discriminating, meaning that even though the data are random uniformly distributed, it could also find some clustering patterns inside the dataset. We employ the Hopkins statistic, a measure probability that the dataset is generated by a uniform distribution. The null hypothesis suggesting a uniform distribution should indicate the value being close to 0.5. With a Hopkins statistic value of `r hop`, we reject the null hypothesis and conclude that the resulting dataset exhibits a high degree of clusterability.

Having established the dataset's suitability for clustering analysis, the subsequent task is to determine the optimal number of clusters for partitioning. This step commonly revolves around optimizing a statistical criterion. An approach involves utilizing the within-cluster sum of squares (WSS), which measures the compactness of resulting clusters---a smaller WSS value indicates a more cohesive clustering. The following figure illustrates the variation in WSS with respect to the number of clusters. While the graph does not display a distinct elbow pattern, we deem it is reasonable to select 4 clusters as the WSS value does not exhibit a substantial decrease beyond this point.

```{r, echo=FALSE}
fviz_nbclust(df, kmeans, method = "wss") +
  geom_vline(xintercept = 4, linetype = 2)+
  labs(subtitle = "Elbow method")
```

We implement k-means clustering with a predetermined value of 4 for better understanding the underlying patterns in the data. As the data contain more than two variables, we use principal component analysis (PCA) to reduce the dimensionality and provide a scatter plot. As depicted in the 2-D cluster plot. The first principal component accounts for 44.4% of the total variation, while the second component explains an additional 12.8%. The cluster plot below indicates the presence of 4 meaningful clusters within the dataset in spite of some overlap between the clusters (especially between cluster 2 and 4).

```{r, echo=FALSE}
km.res <- eclust(df, "kmeans", k = 4, nstart = 25, graph = FALSE)
fviz_cluster(km.res, geom = "point", ellipse.type = "norm",
             palette = "jco", ggtheme = theme_minimal())
```

The dataset is partitioned into 4 clusters, with each containing `r km.res$size[1]`, `r km.res$size[2]`, `r km.res$size[3]`, and `r km.res$size[4]` data points. We can therefore characterize the social-economic profiles of these clusters by examining the distribution of the variables within each cluster. Cluster 3, in particular, has the highest rates of homicide, rural living, poverty and total death. It also has the smallest population, lowest higher education rate and median income. It is then labeled as "Small rural towns with more poverty and less education". In contrast, cluster 4 shows best results among the social-economic factors with highest higher education, median income, but least rates of homicide, rural living, total deaths and poverty. We thus gives it the label "Big cities with more wealth and education". Clusters 1 and 2 fall between Clusters 3 and 4 in various indicators. Cluster 2 outperforms Cluster 1 in higher education rate, lower total death rates, higher median income, and less poverty, despite a slightly higher homicide rate. We notice that the indicators for cluster 2 are similar to the national level, but with less homicide and being less rural. We provide it with the label "Medium-sized cities averaging to national level". Finally, cluster 1 has education, population, poverty, and median income below national averages, along with a more rural profile and a higher percentage of elderly population (and less children/teenager percentage). Therefore, it is labeled as "rural areas with higher elder population". We do not leverage unemployment as a discriminitive factor as it converges around the national level rate across all clusters, even though it tends to be higher in bigger cities.

```{r, echo=FALSE}
cases_f$Cluster <- km.res$cluster
cases_f$death_rate <- deaths_f$`2021-06` / cases_f$`2021-06`
cl1 <- cases_f[cases_f$Cluster == 1,]
cl2 <- cases_f[cases_f$Cluster == 2,]
cl3 <- cases_f[cases_f$Cluster == 3,]
cl4 <- cases_f[cases_f$Cluster == 4,]
clusters <- list(cl1, cl2, cl3, cl4)

tab <- matrix(data=NA, nrow=11, ncol=6)
tab[1,] <- c('', 'Cluster 1', 'Cluster 2', 'Cluster 3', 'Cluster 4', 'National')
tab[,1] <- c("", "Homicide", "Rural", "Higher Education", "Population", "Total Deaths", "Poverty", "Median Income", "Unemployed", "Below 18", "Above 65")

for (i in 1:5) {
  if (i %in% c(1, 2, 3, 4)) {
    cluster <- clusters[[i]]
  } else {
    cluster <- cases_f
  }
  
  tab[2, 1+i] <- round(mean(cluster$Homicide), 4)
  tab[3, 1+i] <- round(mean(cluster$Rural), 4)
  tab[4, 1+i] <- round(mean(cluster$`Higher Education`), 4)
  tab[5, 1+i] <- round(mean(cluster$Population))
  tab[6, 1+i] <- round(mean(cluster$`Total Deaths`), 4)
  tab[7, 1+i] <- round(mean(cluster$Poverty), 4)
  tab[8, 1+i] <- round(mean(cluster$`Median Income`), 4)
  tab[9, 1+i] <- round(mean(cluster$Unemployed), 4)
  tab[10, 1+i] <- round(mean(cluster$`Below 18`), 4)
  tab[11, 1+i] <- round(mean(cluster$`Above 65`), 4)
}

knitr::kable(tab)
```

### Regression trees

var_select <- function(df) {
  df |> select(Smoke, Obesity, `Food Environment`, `Physical inactivity`, Drinking, Uninsured, `death_rate`)
}

all <- var_select(cases_f)
cl1 <- var_select(cl1)
cl2 <- var_select(cl2)
cl3 <- var_select(cl3)
cl4 <- var_select(cl4)
colnames(all) <- make.names(colnames(all))
colnames(cl1) <- make.names(colnames(cl1))
colnames(cl2) <- make.names(colnames(cl2))
colnames(cl3) <- make.names(colnames(cl3))
colnames(cl4) <- make.names(colnames(cl4))

ctrl <- trainControl(method = "cv", number = 5)
grid <- expand.grid(cp = seq(0, 0.04, by = 0.002))

tree1 <- train(death_rate ~ ., 
               data = cl1,      
               method = "rpart",             
               trControl = ctrl,            
               tuneGrid = grid)

tree2 <- train(death_rate ~ ., 
               data = cl2,      
               method = "rpart",             
               trControl = ctrl,            
               tuneGrid = grid)

tree3 <- train(death_rate ~ ., 
               data = cl3,      
               method = "rpart",             
               trControl = ctrl,            
               tuneGrid = grid)

tree4 <- train(death_rate ~ ., 
               data = cl4,      
               method = "rpart",             
               trControl = ctrl,            
               tuneGrid = grid)

tree <- train(death_rate ~ ., 
               data = all,      
               method = "rpart",             
               trControl = ctrl,            
               tuneGrid = grid)
```

After obtaining the four clusters, we are able to analyse the relevant health factors (namely, smoke, obesity, food environment, physical inactivity, drinking and uninsurance rate) that potentially influence the COVID-19 death rate. To explore these relationships, we employ regression trees with the classification and regression trees (CART) algorithm. The generated trees offer an easily interpretable framework for discerning a county's death rate. Starting from the root node that contains all data points, the algorithm sequentially partitions the data based on specific variable values. Each data point is then assigned to a new node through binary division. This process iterates until the stopping criterion is met. However, it is common for trees to become overly complicated such that their interpretability and prediction accuracy. To address this, we implement pre-pruning by controlling the complexity parameter such that a good balance between model simplicity and generality can be ensured. This is done by 5-fold cross validation with grid search on the hyper-parameter and in doing so we choose the one with least resulting RSME.

The generated regression trees help us understand how relevant factors influence the COVID death rate for different kinds of cities. We start with the rural towns with higher elder population (Cluster 1). Beginning at the root node, we observe the mean COVID death rate at 2%, representing 100% of the total data points. Moving towards the first splitting rule, a physical inactivity rate less than 25% corresponds with the lowest death rate of 1.8%, which then encompasses 30% of the total data points. For cases where the physical inactivity rate is larger than or equal to 25%, a new set of splits emerge. Continuing the "if-then" structure, the uninsuarance rate exceeding 19% results in death rate of 0.02%. Conversely, if it is below 19%, we then investigate into the county's food environment index. Should this rate be above 6, the predicted death rate is 2.1%. Conversely, an food environment index less than 6 leads to a highest death rate of 3.3%, which occupies the smallest portion of data among all terminal nodes.

Similar "if-then" rules could be applied on the rest of the trees, where the primary split is usually physical inactivity. Significantly different tree structure appears to belong to small rural towns with more poverty and less education (Cluster 3), where the first determining factor becomes smoking rate. Drinking also plays an important role as it appears several times in deeper layers of the tree.

```{r, echo = FALSE}
rpart.plot(tree1$finalModel, main = "Regression tree for Cluster 1 -- Rural towns with higher elder population")
rpart.plot(tree2$finalModel, main = "Regression tree for Cluster 2 -- Medium-sized cities averaging to national level")
rpart.plot(tree3$finalModel, main = "Regression tree for Cluster 3 -- Small rural towns with more poverty and less education")
rpart.plot(tree4$finalModel, main = "Regression tree for Cluster 4 -- Big cities with more wealth and education")
rpart.plot(tree$finalModel, main = "Regreesion tree for national data")
```
The trees also provide metrics to measure the importance of the variables in its construction. It is calculated by the improvement in the purity that each variable contributes, which, as a result, may be different from the order in which they appear in the tree. Below are the figures of the (scaled) variable importance for the full data and each cluster. As can be seen, for most clusters, the primarily important variable is physical inactivity, followed by uninsuarnce and food and environment. However, for the rural areas with more poverty and less education, the most influential factor becomes uninsurane, and other important factors turn to be smoking, drinking, etc. Conversely, in big cities with more wealth and education, obesity takes the second place in the measurment of variable importance. It is, however, interesting to notice that uninsuarce is ranked not so important on a national level, which could be imputed to the instability of individual trees.

```{r, echo = FALSE}
varImp_plot <- function (tree){
  df <- data.frame(Importance = tree$finalModel$variable.importance)
  df <- df / max(df)
  df |> rownames_to_column() |> 
    rename("Variable" = rowname) |>
    mutate(Variable = forcats::fct_inorder(Variable)) |> 
    ggplot(aes(y = Variable, x = Importance)) + geom_col()
}
plot <- varImp_plot(tree)
plot1 <- varImp_plot(tree1)
plot2 <- varImp_plot(tree2)
plot3 <- varImp_plot(tree3)
plot4 <- varImp_plot(tree4)

plot_grid(plot, NULL, plot1, plot2, plot3, plot4, nrow = 3, ncol = 2, align = "v", labels = c("National", "", "Cluster 1", "Cluster 2", "Cluster 3", "Cluster 4"), label_size = 8)
```

## Conclusion

## References

Almalki A, Gokaraju B, Acquaah Y, Turlapaty A. (2022) Regression analysis for COVID-19 infections and deaths based on food access and health issues. Healthcare 10(2):324.

## Annex

### Links

Github: <https://github.com/wuyuntong/Group_Project>

Data Source:

Health data (2021 CHR CSV Analytic Data): <https://www.countyhealthrankings.org/explore-health-rankings/rankings-data-documentation>

COVID data (cases & deaths): <https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/>

Social-economic data (poverty, unemployment, education, & population): <https://www.ers.usda.gov/data-products/county-level-data-sets/county-level-data-sets-download-data/>

### Data pre-processing

For COVID cases and deaths datasets, we formatted the county FIPS code such that it is a 5-digit string. The FIPS for statewide unallocated cases and deathes is assigned a new value "99999". Variables important to the study(countyFIPS, County Name, State, StateFIPS and the numbers at the end of each month from Jul 2020 to June 2021) are reserved. After that, the case and death numbers are renamed corresponding to each month. A new row for US representing the nationwide cases and deaths is added.

For social-economic datasets, we keep only the countyFIPS and variables mentioned in the section of variable description. For health dataset, we merged county FIPS and state FIPS such that the FIPS code is line with other datasets. The variables for study are selected and are changed from the string type to numeric. Almost all the columns are complete, with no missing values.

For each one of cases and deaths, we join them by the primary key countyFIPS with the rest of the pre-processed datasets. Missing values are deleted. The resulting final ones are cases_f and deaths_f. These two datasets are used for clustering and regression tasks.
