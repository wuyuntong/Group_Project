---
title: "COVID-19 cases and deaths analysis"
format: 
  pdf: default
  html: default
editor: visual
author: Yuntong Wu & Jiaxin Shen
---

## Research question

The COVID-19 crisis has wreaked havoc on the world economy and people's lives. In the US, the impact has been staggering, with nearly 100 million people contracting the virus and over 1 million died as of mid-July, 2023, as reported by USAfacts. From cities to rural towns, it is important for policymakers to stay informed how COVID-19 is spreading and affects families, commerce, and travel to take measures. Our focus on this project is on scrutinizing COVID-19 data at the county level in the US from July 2020 to June 2021---a period marked by the peak severity of the pandemic and the coexistence of various policies. With the project, we aim to gain an understanding of how different factors played a role during the pandemic.

First, our focus revolves around understanding the dynamics of the pandemic's progression within the US. It is crucial to delve into the data and find out whether there are tangible variations in the trends at some critical moments. For instance, we want to see if there is a dramatic difference in the confirmed cases or deaths in different regions and how these numbers evolve as time goes by.

Furthermore, recognizing that the counties are different in various manners, our analysis seeks to uncover patterns of COVID cases and deaths that may be influenced by these differences. Our investigation extends to labeling the counties using the available characteristics. This could be done by using clustering techniques, such that counties with similar characteristics could be categorized into a group and others with disparate characteristics could be categorized into separate groups. By targeting specific cluster groups, policy makers are able to make better informed decisions to contain the spread of the virus or reduce the death rates.

Lastly, this project also incorporates a nationwide exploration of the covariates that contribute to severity of deaths caused by COVID. We consider a pool of health-related factors, including smoking, drinking, obesity, food and environment, and insurance coverage to study their effects. Our chosen methodology involves utilizing regression trees to unravel the inter-relationship with the tree structure for each cluster. This approach also provides a measure of the importance for the factors in COVID caused deaths.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

```{r, echo=FALSE, message= FALSE, warning= FALSE}
here::i_am("Group_Project.Rproj")
library(here)
library(vroom)
library(dplyr)
library(tidyr)
library(ggplot2)
library(knitr)
library(caret)
library(tibble)
library(rpart)
library(rpart.plot)
library(cowplot)
library(patchwork)
library(stringr)
library(factoextra)
library(hopkins)
library(forecast)
library(lubridate)
library(tseries)
library(moments)

set.seed(123)
theme_set(theme_bw())
```

```{r, echo=FALSE, message=FALSE}
health <- vroom(here("data", "analytic_data2021.csv"))
cases <- vroom(here("data", "covid_confirmed_usafacts.csv"))
deaths <- vroom(here("data", "covid_deaths_usafacts.csv"))
edu <- vroom(here("data", "Education.csv"))
pop <- vroom(here("data", "PopulationEstimates.csv"))
pov <- vroom(here("data", "PovertyEstimates.csv"))
ump <- vroom(here("data", "Unemployment.csv"))
```

## Data sets descriptions

To ensure the reliability of our findings, our initial step involves selecting the necessary data for accurate and comprehensive information. The most important information we is the daily cumulative number of cases and deaths across the counties, which are the target variables of our interest. Additionally, health, demographic and social-economic data are also necessary for us to discern their relationship with the COVID deaths rates. For example, people from poor regions may not have support from health insurance, which could become a serious problem if he catches the virus and his condition deteriorates. Given that most of the chosen datasets are very large and contains information not practical for our case study, we focus exclusively on a handful of variables that are directly relevant to our research objectives. Some downloaded files are .xsl and converted .csv. Below are the descriptions of the data sources and variables.

### Data sources

1.Health data: The file analytic_data2021 comes from the County Health Rankings & Roadmaps (CHR&R). County Health Rankings & Roadmaps (CHR&R) is a program of the University of Wisconsin Population Health Institute. The CHR&R program provides data, evidence, guidance, and examples to build awareness of the multiple factors that influence health and support leaders in growing community power to improve health equity.

This file provides various health-related indicators for U.S. counties in 2021, including health behaviors, clinical care, as well as social and economic factors. Our focus is on ten specific variables---Adult smoking, Adult obesity, Food environment index, Physical inactivity, Excessive drinking, Uninsured, Percentage of people below 18 or above 65, rural rates, and homicide. We aim to investigate the correlation between these health metrics and COVID-19 death rates, seeking insights into the interplay between various factors and the pandemic's impact on communities.

2.COVID data: The files covid_confirmed_usafacts and covid_deaths_usafacts come from USAFacts. USAFacts currently counts presumptive positive cases as confirmed cases, as this is in line with how the CDC reports data. For deaths, USAFacts only takes those from state and local agencies if the virus played a direct role in causing death.

These two files provide daily cumulative data on confirmed cases and deaths attributed to the pandemic, organized by county in the United States spanning from January 2020 to July 2023. Notably, there are some cases counted at the state level are not allocated to counties due to lack of information. We select the number at the end of each month as monthly data to make it more intuitive and representative. The COVID confirmed cases number and COVID death number are the target variables of our analysis.

3.Social-economic and demographic data: These four files Education, PopulationEstimates, PovertyEstimates and Unemployment, come from USDA's & Economic Research Service, which anticipate trends and emerging issues in agriculture, food, the environment, and rural America and to conduct high-quality, objective economic research to inform and enhance public and private decision making.

The Education dataset comes from multiple programs, including US Census Bureau and American Community Service. This file provides the basic information on the educational attainment of counties in the United States from 2017 to 2021. We focus on the variable, number of people having bachelor's degree or above, in this dataset.

PopulationEstimates are from U.S. Census Bureau for 1990, 2000, 2010, and 2020 Censuses of Population, and Population Estimates Program (PEP). We select population and total number of deaths for analysis.

PovertyEstimates are model-based estimates from the U.S. Census Bureau's Small Area Income and Poverty Estimate (SAIPE) program. For counties and states, the program models income and poverty estimates by combining survey data with population estimates and administrative records. The data file file includes the estimated statistics of counties in the United States in 2021. The number of people of all ages in poverty 2021 and median income are selected for analysis.

The county and State unemployment rates are from the Bureau of Labor Statistics (BLS) Local Area Unemployment Statistics (LAUS) program. The Local Area Unemployment Statistics (LAUS) program is a federal-state cooperative effort in which monthly estimates of total employment and unemployment are prepared for over 7,600 areas. This file includes overall employment status by county in the United States from 2000 to 2022. Median household is from the U.S. Census Bureau's Small Area Income and Poverty Estimate (SAIPE) program as in the previous dataset. The number of unemployed for each county is selected for this study.

### Basic information about the data files

```{r, echo=FALSE}
info <- function(df) {
  data.frame(file = deparse(substitute(df)), row_number = nrow(df), col_number = ncol(df), missing_number = sum(is.na(df)), rows_with_missing_values = sum(apply(df, 1, function(row) any(is.na(row)))))
}
```

```{r, echo=FALSE}
t_info_health <- info(health)

t_info_cases <- info(cases)

t_info_deaths <- info(deaths)

t_info_edu <- info(edu)

t_info_pop <- info(pop)

t_info_pov <- info(pov)

t_info_ump <- info(ump)

bind_rows(t_info_health, t_info_cases, t_info_deaths, t_info_edu, t_info_pop, t_info_pov, t_info_ump) |> knitr::kable()
```

### Description of variables

Below is the description of variables that are used in the project. For other variables, we refer interested readers to the data sources.

countyFIPS: Federal Information Processing Standard (FIPS) Code.

State: State abbreviation.

County Name: county names.

cases_mon: containing cumulative COVID-19 confirmed cases number at the end of each month from July 2020 to June 2021.

deaths_mon: containing cumulative COVID-19 death number at the end of each month from July 2020 to June 2021.

Smoking: Percentage of adults who are current smokers (age-adjusted).

Obesity: Percentage of the adult population (age 20 and older) that reports a body mass index (BMI) greater than or equal to 30 kg/m2.

Food environment index: Index of factors that contribute to a healthy food environment, from 0 (worst) to 10 (best).

Physical inactivity: Percentage of adults age 20 and over reporting no leisure-time physical activity.

Drinking: Percentage of adults reporting binge or heavy drinking (age-adjusted).

Uninsured: Percentage of population under age 65 without health insurance.

Homicide: Number of deaths due to homicide per 100,000 population.

Rural: Percentage of population living in a rural area.

Below 18: Percentage of population below 18 years of age.

Above 65: Percentage of population ages 65 and older.

Poverty: Percentage of estimated number of people of all ages in poverty 2021.

Unemployed: Percentage of unemployment in 2021.

Population: 4/1/2020 resident Census 2020 population.

Median Income: Estimate of median household income in 2021.

Total Deaths: Percentage of death number in period 7/1/2020 to 6/30/2021.

Higher Education: Percentage of adults with a bachelor's degree or higher, 2017-21.

## Data analysis
```{r, echo=FALSE}
cov_clean <- function(df) {
  df$countyFIPS <- df$countyFIPS |>
    as.character() |>
    str_pad(5, pad = "0")

  df$countyFIPS <- ifelse(df$`County Name` == "Statewide Unallocated", "99999", df$countyFIPS)

  df <- df |>
    select(
      countyFIPS, `County Name`, State, StateFIPS,
      `2020-07-31`, `2020-08-31`, `2020-09-30`, `2020-10-31`,
      `2020-11-30`, `2020-12-31`, `2021-01-31`, `2021-02-28`,
      `2021-03-31`, `2021-04-30`, `2021-05-31`, `2021-06-30`
    ) |>
    rename(
      `2020-07` = `2020-07-31`,
      `2020-08` = `2020-08-31`,
      `2020-09` = `2020-09-30`,
      `2020-10` = `2020-10-31`,
      `2020-11` = `2020-11-30`,
      `2020-12` = `2020-12-31`,
      `2021-01` = `2021-01-31`,
      `2021-02` = `2021-02-28`,
      `2021-03` = `2021-03-31`,
      `2021-04` = `2021-04-30`,
      `2021-05` = `2021-05-31`,
      `2021-06` = `2021-06-30`
    )

  US <- data.frame(
    countyFIPS = "00000",
    `County Name` = "United States",
    State = NA,
    StateFIPS = NA,
    `2020-07` = NA,
    `2020-08` = NA,
    `2020-09` = NA,
    `2020-10` = NA,
    `2020-11` = NA,
    `2020-12` = NA,
    `2021-01` = NA,
    `2021-02` = NA,
    `2021-03` = NA,
    `2021-04` = NA,
    `2021-05` = NA,
    `2021-06` = NA,
    check.names = FALSE
  )

  df <- bind_rows(US, df)
}
```

```{r, echo=FALSE}
cases_mon <- cov_clean(cases)
deaths_mon <- cov_clean(deaths)
```

```{r, echo=FALSE}
edu_c <- edu |>
  select(`Federal Information Processing Standard (FIPS) Code`, `Bachelor's degree or higher, 2017-21`) |>
  rename(
    countyFIPS = `Federal Information Processing Standard (FIPS) Code`,
    `Higher Education` = `Bachelor's degree or higher, 2017-21`
  )
```

```{r, echo=FALSE}
pop_c <- pop |>
  select(FIPStxt, CENSUS_2020_POP, DEATHS_2021) |>
  rename(
    countyFIPS = FIPStxt,
    Population = CENSUS_2020_POP,
    `Total Deaths` = DEATHS_2021
  )
```

```{r, echo=FALSE}
pov_c <- pov |>
  select(FIPS_Code, POVALL_2021, MEDHHINC_2021) |>
  rename(
    countyFIPS = FIPS_Code,
    Poverty = POVALL_2021,
    `Median Income` = MEDHHINC_2021
  )
```

```{r, echo=FALSE}
ump_c <- ump |>
  select(FIPS_Code, Unemployed_2021) |>
  rename(
    countyFIPS = FIPS_Code,
    Unemployed = Unemployed_2021
  )
```

```{r, echo=FALSE}
health_c <- health[2:nrow(health), ] |>
  mutate(countyFIPS = paste(`State FIPS Code`, `County FIPS Code`, sep = "")) |>
  select(countyFIPS, `Adult smoking raw value`, `Adult obesity raw value`, `Food environment index raw value`, `Physical inactivity raw value`, `Excessive drinking raw value`, `Uninsured raw value`, `Homicides raw value`, `% Rural raw value`, `% below 18 years of age raw value`, `% 65 and older raw value`) |>
  rename(
    Smoking = `Adult smoking raw value`,
    Obesity = `Adult obesity raw value`,
    `Food Environment` = `Food environment index raw value`,
    `Physical Inactivity` = `Physical inactivity raw value`,
    Drinking = `Excessive drinking raw value`,
    Uninsured = `Uninsured raw value`,
    Homicide = `Homicides raw value`,
    Rural = `% Rural raw value`,
    `Below 18` = `% below 18 years of age raw value`,
    `Above 65` = `% 65 and older raw value`
  ) |>
  mutate(
    Smoking = as.numeric(Smoking),
    Obesity = as.numeric(Obesity),
    `Food Environment` = as.numeric(`Food Environment`),
    `Physical Inactivity` = as.numeric(`Physical Inactivity`),
    Drinking = as.numeric(Drinking),
    Uninsured = as.numeric(Uninsured),
    Homicide = as.numeric(Homicide),
    Rural = as.numeric(Rural),
    `Below 18` = as.numeric(`Below 18`),
    `Above 65` = as.numeric(`Above 65`)
  )
```

```{r, echo=FALSE}
cases_f <- cases_mon |>
  left_join(health_c, by = "countyFIPS") |>
  left_join(edu_c, by = "countyFIPS") |>
  left_join(pop_c, by = "countyFIPS") |>
  left_join(pov_c, by = "countyFIPS") |>
  left_join(ump_c, by = "countyFIPS") |>
  na.omit()

cases_f$`Higher Education` <- cases_f$`Higher Education` / cases_f$Population
cases_f$`Total Deaths` <- cases_f$`Total Deaths` / cases_f$Population
cases_f$Poverty <- cases_f$Poverty / cases_f$Population
cases_f$Unemployed <- cases_f$Unemployed / cases_f$Population


deaths_f <- deaths_mon |>
  left_join(health_c, by = "countyFIPS") |>
  left_join(edu_c, by = "countyFIPS") |>
  left_join(pop_c, by = "countyFIPS") |>
  left_join(pov_c, by = "countyFIPS") |>
  left_join(ump_c, by = "countyFIPS") |>
  na.omit()

deaths_f$`Higher Education` <- deaths_f$`Higher Education` / deaths_f$Population
deaths_f$`Total Deaths` <- deaths_f$`Total Deaths` / deaths_f$Population
deaths_f$Poverty <- deaths_f$Poverty / deaths_f$Population
deaths_f$Unemployed <- deaths_f$Unemployed / deaths_f$Population
```
After obtaining the data, we analyze them from several aspects. Firstly, we present the overall graphical representations of the data, qualitatively discussing the trends (in months) in the COVID infection cases and deaths from a state level. Secondly, we conduct time series analysis on the national total cases and deaths, examining whether there are temporal correlations. We then fit an ARIMA model to quantitatively analyze the trend of data over time. Subsequently, we employ the K-means clustering analysis method to cluster different countries based on social-economic and demographic factors. Finally, we use the regression tree method to analyse the impact of health-related variables on the death rate.

The visual representations below shows a persistent increase in the overall count of COVID-19 infection cases and associated deaths, characterized by an S-shaped curve. Notably, these two numbers are marked by a slow and steady increase in the period from June 2020 and October 2020. During the winter months (November 2020 to January 2021), a dramatic surge is evident across all states, contributing to a substantial spike in both new cases and deaths. In subsequent months (Feburary 2021 to June 2021), the new cases and deaths slow down to the initial level. Nevertheless, there appears to be a small peak in March and April 2021, when the delta variant becomes prevalent in the states.

Geographically, the distribution of cases and deaths is more pronounced in densely populated, urbanized and prosperous regions, such as California, New York state, and Texas, while relatively fewer incidents are observed in rural and sparsely populated areas. The spatial imbalance motivates our exploration into the relationships between COVID-19 cases and deaths and various contributing factors by segmenting the different regions to better understand the dynamics on stage.

```{r, echo=FALSE, warning=FALSE}
cases_mon |>
  group_by(State) |>
  summarise(across(starts_with("202"), sum, na.rm = TRUE)) |>
  pivot_longer(cols = starts_with("202"), names_to = "month", values_to = "count")|>   na.omit()|>
  ggplot(aes(x = month, y = count, group = State, color = State)) +
  geom_line() +
  labs(title = "Total cases reported across all 50 states from July 2020 to June 2021") +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(margin = margin(b = 40))
  )
```

```{r, echo=FALSE}
deaths_mon |>
  group_by(State) |>
  summarise(across(starts_with("202"), sum, na.rm = TRUE)) |>
  pivot_longer(cols = starts_with("202"), names_to = "month", values_to = "count")|>   na.omit() |>
  ggplot(aes(x = month, y = count, group = State, color = State)) +
  geom_line() +
  labs(title = "Total deaths reported across all 50 states from July 2020 to June 2021") +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(margin = margin(b = 40))
  )
```

```{r, echo=FALSE}
cases_mon |>
  group_by(State) |>
  summarise(across(starts_with("202"), sum, na.rm = TRUE)) |>
  pivot_longer(cols = starts_with("202"), names_to = "month", values_to = "count") |>
  group_by(State) |>
  mutate_at(vars(count), list(~ .x - lag(.x))) |>
  na.omit() |>
  ggplot(aes(x = month, y = count, group = State, color = State)) +
  geom_line() +
  labs(title = "New cases reported across all 50 states from August 2020 to June 2021") +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(margin = margin(b = 40))
  )
```

```{r, echo=FALSE}
deaths_mon |>
  group_by(State) |>
  summarise(across(starts_with("202"), sum, na.rm = TRUE)) |>
  pivot_longer(cols = starts_with("202"), names_to = "month", values_to = "count") |>
  group_by(State) |>
  mutate_at(vars(count), list(~ .x - lag(.x))) |>
  na.omit() |>
  ggplot(aes(x = month, y = count, group = State, color = State)) +
  geom_line() +
  labs(title = "New deaths reported across all 50 states from August 2020 to June 2021") +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(margin = margin(b = 40))
  )
```
### Time series analysis of national cases and deaths

Our focus now shifts to discerning specific trends in cases and deaths at the national level within the United States. For this, we examine daily cumulative data spanning from July 1, 2020, to June 30, 2021. We use the ARIMA model handle trend and seasonality and the resulting series is treated as stationary time series. The model is constructed with a combination of its lagged time series values (“AR”) and moving average of lagged forecast errors (“MA”). An ARIMA model is typically specified by a tuple (p, d, q), where p and q define the orders of AR and MA, and d specifies the order of differencing operation, in the form of $(1 - \sum_{i=1}^{p} \phi_{i} L^{i} ) \; (1-L)^{d} \; X_{t} = (1 + \sum_{i = 1}^{q} \theta_{i}L^{i}) \;\epsilon_{t}$.

The advantage of the ARIMA model is that the model is simple and only requires endogenous variables without the help of other exogenous variables. Nevertheless, ARIMA model also has disadvantages: the time series data is required to be stable, or be stable after differentiation. Essentially it can only capture linear relationships, not non-linear relationships. In order to test the accuracy of model fitting, we divide the data set into a training set and a test set. The initial 70% of the data (1-Jul-2020 - 11-Mar-2021) is used as the training set and the remaining 30% (12-Mar-2021 - 30-June-2021) is utilized as the test set.

#### National cases

```{r}
national_cases <- cases |>
  select(starts_with("202")) |>
  summarise_all(sum, na.rm = TRUE) |>
  select(`2020-07-01`:`2021-06-30`) |>
  pivot_longer(everything(), names_to = "Date", values_to = "Cases")
```


```{r}
case_ts <- log(ts(national_cases$Cases))
par(mfrow = c(1, 2))
p_orig <- plot.ts(case_ts, main = "Original data", xlab = "Time", ylab = "Cases")
p_2diff <- plot.ts(diff(diff(case_ts)), main = "Second-order differenced  data", ylab = "Second-order Differenced Cases", xlab = "Time")
par(mfrow = c(1, 1))
adf1 <- adf.test(diff(diff(case_ts)))
```

With an visual insepction, we find that the original data (after taking logarithm) is not stationary.The stability is achieved after second-order difference. By applying the ADF test on the second-order difference data, we find the test statistic is `r adf1$statistic` with a lag order of 6, resulting in a p-value of `r adf1$p.value`. We thus reject the null hypothesis (under the 5% significance level), and the stationarity is supported for the second-order differenced series.

By minimizing AIC, the obtained ARIMA model is an ARIMA(2,2,2) with the estimated cofficients $\phi_{1} = 1.1897, \phi_{2} = -0.7419, \theta_{1} = -1.4758 \; \text{and} \; \phi_{2} = 0.7469$. After inspecting the residuals, we find it tends to be a white noise, as there are few cases of significant autocorrelation despite its distribution slightly deviates from normal.



```{r}
cutoff_index <- floor(0.7 * length(case_ts))

train_case <- case_ts[1:cutoff_index]
test_case <- case_ts[cutoff_index : length(case_ts)] |> ts(start = as.character(cutoff_index + 1))
model_case <- auto.arima(train_case, ic = "aic")
checkresiduals(model_case, test = FALSE)
forecast1 <- forecast(model_case, h = floor(0.3 * length(case_ts)) + 1)
plot(forecast1)
lines(test_case, lwd = 2, col = "red") 
mape1 <- mean(abs((test_case - forecast1$mean) / test_case)) * 100
```

In the subsequent analysis, we assess the forecasting accuracy of the model in the period from the remaining 30% of the data. The actual data curve in red and fitted curve in blue, along with 80% and 95% confidence intervals are represented. The high predictability is also validated by the value of mean absolute percentage error of `r mape1`%, suggesting a high level of accuracy.

#### National deaths

```{r}
national_deaths <- deaths |>
  select(starts_with("202")) |>
  mutate(across(everything(), as.numeric)) |>
  summarise_all(sum, na.rm = TRUE) |>
  select(`2020-07-01`:`2021-06-30`) |>
  pivot_longer(everything(), names_to = "Date", values_to = "Deaths")
```

```{r}
death_ts <- log(ts(national_deaths$Deaths))
par(mfrow = c(1, 2))
p_orig_d <-plot.ts(death_ts, main = "Original data", xlab = "Time", ylab = "Deaths")
p_2diff_d <- plot.ts(diff(diff(death_ts)), main = "Second-order differenced data", ylab = "Second-order Differenced Deaths", xlab = "Time")
par(mfrow = c(1, 1))
adf2 <- adf.test(diff(diff(case_ts)))
```

```{r}
cutoff_index <- floor(0.7 * length(death_ts))
train_death <- death_ts[1:cutoff_index]
test_death <- death_ts[cutoff_index : length(death_ts)] |>
  ts(start = as.character(cutoff_index + 1))
```

```{r}
model_death <- auto.arima(train_death, ic = "aic")
checkresiduals(model_death, test = FALSE)
forecast2 <- forecast(model_death, h = floor(0.3 * length(case_ts)) + 1)
mape2 <- mean(abs((test_case - forecast2$mean) / test_case)) * 100
plot(forecast2)
lines(test_death, lwd = 2, col = "red")
```

By performing similar analysis on the death numbers, we obtain an ARIMA(5,2,2) with estimated coefficients $\phi_{1} = 0.3002, \phi_{2} = -0.5749, \phi_{5} = -0.3117, \phi_{4} = -0.2904, \phi_{5} = -0.3423, \theta_{1} = -0.9409, \theta_{2} = 0.5743$. Following the previous analysis, the residuals of the model also tend to be white noise. The MAPE for the model is `r mape2`%, indicating a moderate level of accuracy since the model tends to overestimate the number of deaths.

### An inspection on covariates

We now leverage national county-level data to explicate the distribution characteristics of the factors associated with each county. In the context of health-related factors, certain variables exhibit normality, for example, smoking, drinking, obesity, and uninsurance, with skewness values proximate to 0 and kurtosis close to 3. In addition, physical inactivity is characterized by unskewness and thinner tails, suggesting low probabilities for cases of extrem low or high inactivity rates. The food environment index, in contrast, is more left-skewed and fatter tailed. This implies that quite a few counties have relatively unhealthy food environment.

```{r}
p_smoking <- ggplot(data = cases_f, aes(x = Smoking)) +
  geom_histogram(color = "black", bins = 50) +
  labs(x = "Smoking rate", y = "Frequency")

p_obes <- ggplot(data = cases_f, aes(x = Obesity)) +
  geom_histogram(color = "black", bins = 50) +
  labs(x = "Obesity rate", y = "Frequency")

p_food <- ggplot(data = cases_f, aes(x = `Food Environment`)) +
  geom_histogram(color = "black", bins = 50) +
  labs(x = "Food Environment", y = "Frequency")

p_phys <- ggplot(data = cases_f, aes(x = `Physical Inactivity`)) +
  geom_histogram(color = "black", bins = 50) +
  labs(x = "Physical Inactivity", y = "Frequency")

p_drink <- ggplot(data = cases_f, aes(x = `Drinking`)) +
  geom_histogram(color = "black", bins = 50) +
  labs(x = "Drinking rate", y = "Frequency")

p_unins <- ggplot(data = cases_f, aes(x = `Uninsured`)) +
  geom_histogram(color = "black", bins = 50) +
  labs(x = "Uninsured rate", y = "Frequency")

plot_grid(p_smoking, p_obes, p_food, p_phys, p_drink, p_unins, nrow = 2, ncol = 3, align = "v")

tab_dis <- function(df, name) {
  df %>%
    summarise(
      Variable = name,
      Max = max(.data[[name]], na.rm = TRUE),
      Min = min(.data[[name]], na.rm = TRUE),
      Mean = mean(.data[[name]], na.rm = TRUE),
      Median = median(.data[[name]], na.rm = TRUE),
      Variance = var(.data[[name]], na.rm = TRUE),
      Skewness = skewness(.data[[name]], na.rm = TRUE),
      Kurtosis = kurtosis(.data[[name]], na.rm = TRUE)
    )
}

t_smok <- tab_dis(cases_f, "Smoking")
t_drink <- tab_dis(cases_f, "Drinking")
t_obs <- tab_dis(cases_f, "Obesity")
t_uni <- tab_dis(cases_f, "Uninsured")
t_phs <- tab_dis(cases_f, "Physical Inactivity")
t_food <- tab_dis(cases_f, "Food Environment")

bind_rows(t_smok, t_drink, t_obs, t_uni, t_phs, t_food) |> knitr::kable(digits = 3)
```

For social-economic and demographic variables, all of them are right-skewed and most are characterized with fat tails, especially population, where there occurs to be a number of cities with large population. The dispersion in these statistics also lends power in clustering these counties based on these factors. For the variable rural and total death rates, the kurtosis is low, suggesting there is a lack of extreme values and a more uniform-like distribution.

```{r}
p_hom <- ggplot(data = cases_f, aes(x = `Homicide`)) +
  geom_histogram(color = "black", bins = 50) +
  labs(x = "Homicide", y = "Frequency")

p_rural <- ggplot(data = cases_f, aes(x = `Rural`)) +
  geom_histogram(color = "black", bins = 50) +
  labs(x = "Rural", y = "Frequency")

p_hedu <- ggplot(data = cases_f, aes(x = `Higher Education`)) +
  geom_histogram(color = "black", bins = 50) +
  labs(x = "Higher education", y = "Frequency")

p_pop <- ggplot(data = cases_f, aes(x = `Population`)) +
  geom_histogram(color = "black", bins = 50) +
  labs(x = "Population", y = "Frequency") + 
  theme( axis.text.x = element_text(angle = 45, hjust = 1), 
         plot.title = element_text(margin = margin(b = 40))
  )
  
p_td <- ggplot(data = cases_f, aes(x = `Total Deaths`)) +
  geom_histogram(color = "black", bins = 50) +
  labs(x = "Total Deaths", y = "Frequency")

p_pov <- ggplot(data = cases_f, aes(x = `Poverty`)) +
  geom_histogram(color = "black", bins = 50) +
  labs(x = "poverty", y = "Frequency")

p_inc <- ggplot(data = cases_f, aes(x = `Median Income`)) +
  geom_histogram(color = "black", bins = 50) +
  labs(x = "Median Income", y = "Frequency")

p_unemp <- ggplot(data = cases_f, aes(x = `Unemployed`)) +
  geom_histogram(color = "black", bins = 50) +
  labs(x = "Unemployed", y = "Frequency")

p_18 <- ggplot(data = cases_f, aes(x = `Below 18`)) +
  geom_histogram(color = "black", bins = 50) +
  labs(x = "Below 18", y = "Frequency")

p_65 <- ggplot(data = cases_f, aes(x = `Above 65`)) +
  geom_histogram(color = "black", bins = 50) +
  labs(x = "Above 65", y = "Frequency")

plot_grid(p_hom, p_rural, p_hedu, p_pop, p_td, p_pov, p_inc, p_unemp, p_18, p_65, NULL, NULL, nrow = 4, ncol = 3, align = "v")

t_homi <- tab_dis(cases_f, "Homicide")
t_rural <- tab_dis(cases_f, "Rural")
t_hedu <- tab_dis(cases_f, "Higher Education")
t_pop <- tab_dis(cases_f, "Population")
t_tdeath <- tab_dis(cases_f, "Total Deaths")
t_pov <- tab_dis(cases_f, "Poverty")
t_inc <- tab_dis(cases_f, "Median Income")
t_unemp <- tab_dis(cases_f, "Unemployed")
t_18 <- tab_dis(cases_f, "Below 18")
t_65 <- tab_dis(cases_f, "Above 65")

bind_rows(t_homi, t_rural, t_hedu, t_pop, t_tdeath, t_pov, t_inc, t_unemp, t_18, t_65) |> knitr::kable(digits = 3)
```



### Clustering analysis

```{r, echo=FALSE}
df1 <- cases_f[, c("Higher Education", "Population", "Total Deaths", "Poverty", "Median Income", "Unemployed", "Homicide", "Rural", "Below 18", "Above 65")]
df <- as.data.frame(scale(df1))
hop <- hopkins(df)
```

We prepare our dataset for clustering analysis, which involves the extraction of all variables, excluding both the number of cases and identification variables for each county. The dataset is standardized to remove the effect of scales on the clustering. We evaluate the validity of clustering by assessing its clustering tendency because the most clustering methods are not discriminating, meaning that even though the data are random uniformly distributed, it could also find some clustering patterns inside the dataset. We employ the Hopkins statistic, a measure probability that the dataset is generated by a uniform distribution. The null hypothesis suggesting a uniform distribution should indicate the value being close to 0.5. With a Hopkins statistic value of `r hop`, we reject the null hypothesis and conclude that the resulting dataset exhibits a high degree of clusterability.

Having established the dataset's suitability for clustering analysis, the subsequent task is to determine the optimal number of clusters for partitioning. This step commonly revolves around optimizing a statistical criterion. An approach involves utilizing the within-cluster sum of squares (WSS), which measures the compactness of resulting clusters---a smaller WSS value indicates a more cohesive clustering. The following figure illustrates the variation in WSS with respect to the number of clusters. While the graph does not display a distinct elbow pattern, we deem it is reasonable to select 4 clusters as the WSS value does not exhibit a substantial decrease beyond this point.

```{r, echo=FALSE}
fviz_nbclust(df, kmeans, method = "wss") +
  geom_vline(xintercept = 4, linetype = 2) +
  labs(subtitle = "Elbow method")
```

We implement k-means clustering with a predetermined value of 4 for better understanding the underlying patterns in the data. As the data contain more than two variables, we use principal component analysis (PCA) to reduce the dimensionality and provide a scatter plot. As depicted in the 2-D cluster plot. The first principal component accounts for 44.4% of the total variation, while the second component explains an additional 12.8%. The cluster plot below indicates the presence of 4 meaningful clusters within the dataset in spite of some overlap between the clusters (especially between cluster 2 and 4).

```{r, echo=FALSE}
km.res <- eclust(df, "kmeans", k = 4, nstart = 25, graph = FALSE)
fviz_cluster(km.res,
  geom = "point", ellipse.type = "norm",
  palette = "jco", ggtheme = theme_minimal()
)
```

The dataset is partitioned into 4 clusters, with each containing `r km.res$size[1]`, `r km.res$size[2]`, `r km.res$size[3]`, and `r km.res$size[4]` data points. We can therefore characterize the social-economic profiles of these clusters by examining the distribution of the variables within each cluster. Cluster 3, in particular, has the highest rates of homicide, rural living, poverty and total death. It also has the smallest population, lowest higher education rate and median income. It is then labeled as "Small rural towns with more poverty and less education". In contrast, cluster 4 shows best results among the social-economic factors with highest higher education, median income, but least rates of homicide, rural living, total deaths and poverty. We thus gives it the label "Big cities with more wealth and education". Clusters 1 and 2 fall between Clusters 3 and 4 in various indicators. Cluster 2 outperforms Cluster 1 in higher education rate, lower total death rates, higher median income, and less poverty, despite a slightly higher homicide rate. We notice that the indicators for cluster 2 are similar to the national level, but with less homicide and being less rural. We provide it with the label "Medium-sized cities averaging to national level". Finally, cluster 1 has education, population, poverty, and median income below national averages, along with a more rural profile and a higher percentage of elderly population (and less children/teenager percentage). Therefore, it is labeled as "rural areas with higher elder population". We do not leverage unemployment as a discriminitive factor as it converges around the national level rate across all clusters, even though it tends to be higher in bigger cities.

```{r, echo=FALSE}
cases_f$Cluster <- km.res$cluster
cases_f$death_rate <- deaths_f$`2021-06` / cases_f$`2021-06`
cl1 <- cases_f[cases_f$Cluster == 1, ]
cl2 <- cases_f[cases_f$Cluster == 2, ]
cl3 <- cases_f[cases_f$Cluster == 3, ]
cl4 <- cases_f[cases_f$Cluster == 4, ]
clusters <- list(cl1, cl2, cl3, cl4)

tab <- matrix(data = NA, nrow = 11, ncol = 6)
tab[1, ] <- c("", "Cluster 1", "Cluster 2", "Cluster 3", "Cluster 4", "National")
tab[, 1] <- c("", "Homicide", "Rural", "Higher Education", "Population", "Total Deaths", "Poverty", "Median Income", "Unemployed", "Below 18", "Above 65")

for (i in 1:5) {
  if (i %in% c(1, 2, 3, 4)) {
    cluster <- clusters[[i]]
  } else {
    cluster <- cases_f
  }

  tab[2, 1 + i] <- round(mean(cluster$Homicide), 4)
  tab[3, 1 + i] <- round(mean(cluster$Rural), 4)
  tab[4, 1 + i] <- round(mean(cluster$`Higher Education`), 4)
  tab[5, 1 + i] <- round(mean(cluster$Population))
  tab[6, 1 + i] <- round(mean(cluster$`Total Deaths`), 4)
  tab[7, 1 + i] <- round(mean(cluster$Poverty), 4)
  tab[8, 1 + i] <- round(mean(cluster$`Median Income`), 4)
  tab[9, 1 + i] <- round(mean(cluster$Unemployed), 4)
  tab[10, 1 + i] <- round(mean(cluster$`Below 18`), 4)
  tab[11, 1 + i] <- round(mean(cluster$`Above 65`), 4)
}

knitr::kable(tab)
```

### Regression trees

```{r, echo = FALSE}
var_select <- function(df) {
  df |> select(Smoking, Obesity, `Food Environment`, `Physical Inactivity`, Drinking, Uninsured, `death_rate`)
}

all <- var_select(cases_f)
cl1 <- var_select(cl1)
cl2 <- var_select(cl2)
cl3 <- var_select(cl3)
cl4 <- var_select(cl4)
colnames(all) <- make.names(colnames(all))
colnames(cl1) <- make.names(colnames(cl1))
colnames(cl2) <- make.names(colnames(cl2))
colnames(cl3) <- make.names(colnames(cl3))
colnames(cl4) <- make.names(colnames(cl4))

ctrl <- trainControl(method = "cv", number = 5)
grid <- expand.grid(cp = seq(0, 0.04, by = 0.002))

tree1 <- train(death_rate ~ .,
  data = cl1,
  method = "rpart",
  trControl = ctrl,
  tuneGrid = grid
)

tree2 <- train(death_rate ~ .,
  data = cl2,
  method = "rpart",
  trControl = ctrl,
  tuneGrid = grid
)

tree3 <- train(death_rate ~ .,
  data = cl3,
  method = "rpart",
  trControl = ctrl,
  tuneGrid = grid
)

tree4 <- train(death_rate ~ .,
  data = cl4,
  method = "rpart",
  trControl = ctrl,
  tuneGrid = grid
)

tree <- train(death_rate ~ .,
  data = all,
  method = "rpart",
  trControl = ctrl,
  tuneGrid = grid
)
```

After obtaining the four clusters, we are able to analyse the relevant health factors (namely, smoke, obesity, food environment, physical inactivity, drinking and uninsurance rate) that potentially influence the COVID-19 death rate. To explore these relationships, we employ regression trees with the classification and regression trees (CART) algorithm. The generated trees offer an easily interpretable framework for discerning a county's death rate. Starting from the root node that contains all data points, the algorithm sequentially partitions the data based on specific variable values. Each data point is then assigned to a new node through binary division. This process iterates until the stopping criterion is met. However, it is common for trees to become overly complicated such that their interpretability and prediction accuracy. To address this, we implement pre-pruning by controlling the complexity parameter such that a good balance between model simplicity and generality can be ensured. This is done by 5-fold cross validation with grid search on the hyper-parameter and in doing so we choose the one with least resulting RSME.

The generated regression trees help us understand how relevant factors influence the COVID death rate for different kinds of cities. We start with the rural towns with higher elder population (Cluster 1). Beginning at the root node, we observe the mean COVID death rate at 2%, representing 100% of the total data points. Moving towards the first splitting rule, a physical inactivity rate less than 25% corresponds with the lowest death rate of 1.8%, which then encompasses 30% of the total data points. For cases where the physical inactivity rate is larger than or equal to 25%, a new set of splits emerge. Continuing the "if-then" structure, the uninsuarance rate exceeding 19% results in death rate of 0.02%. Conversely, if it is below 19%, we then investigate into the county's food environment index. Should this rate be above 6, the predicted death rate is 2.1%. Conversely, an food environment index less than 6 leads to a highest death rate of 3.3%, which occupies the smallest portion of data among all terminal nodes.

Similar "if-then" rules could be applied on the rest of the trees, where the primary split is usually physical inactivity. Significantly different tree structure appears to belong to small rural towns with more poverty and less education (Cluster 3), where the first determining factor becomes smoking rate. Drinking also plays an important role as it appears several times in deeper layers of the tree.

```{r, echo = FALSE}
rpart.plot(tree1$finalModel, main = "Regression tree for Cluster 1 -- Rural towns with higher elder population")
rpart.plot(tree2$finalModel, main = "Regression tree for Cluster 2 -- Medium-sized cities averaging to national level")
rpart.plot(tree3$finalModel, main = "Regression tree for Cluster 3 -- Small rural towns with more poverty and less education")
rpart.plot(tree4$finalModel, main = "Regression tree for Cluster 4 -- Big cities with more wealth and education")
rpart.plot(tree$finalModel, main = "Regreesion tree for national data")
```

The trees also provide metrics to measure the importance of the variables in its construction. It is calculated by the improvement in the purity that each variable contributes, which, as a result, may be different from the order in which they appear in the tree. Below are the figures of the (scaled) variable importance for the full data and each cluster. As can be seen, for most clusters, the primarily important variable is physical inactivity, followed by uninsuarnce and food and environment. However, for the rural areas with more poverty and less education, the most influential factor becomes uninsurane, and other important factors turn to be smoking, drinking, etc. Conversely, in big cities with more wealth and education, obesity takes the second place in the measurment of variable importance. It is, however, interesting to notice that uninsuarce is ranked not so important on a national level, which could be imputed to the instability of individual trees.

```{r, echo = FALSE}
varImp_plot <- function(tree) {
  df <- data.frame(Importance = tree$finalModel$variable.importance)
  df <- df / max(df)
  df |>
    rownames_to_column() |>
    rename("Variable" = rowname) |>
    mutate(Variable = forcats::fct_inorder(Variable)) |>
    ggplot(aes(y = Variable, x = Importance)) +
    geom_col()
}
plot <- varImp_plot(tree)
plot1 <- varImp_plot(tree1)
plot2 <- varImp_plot(tree2)
plot3 <- varImp_plot(tree3)
plot4 <- varImp_plot(tree4)

plot_grid(plot, NULL, plot1, plot2, plot3, plot4, nrow = 3, ncol = 2, align = "v", labels = c("National", "", "Cluster 1", "Cluster 2", "Cluster 3", "Cluster 4"), label_size = 8)
```

## Conclusion

This report delves into the dynamics of COVID-19 infections and deaths across U.S. counties between June 2020 and June 2021.we conduct both qualitative and time series analyses to gain insights into the overall COVID cases and deaths. In our findings, t there exists large difference in different states in the size of the increase of cases and deaths but the overall trend is observed similarly across the states. Also, leveraging ARIMA enables to leverage moving dynamics of the make predictions, particularly in the COVID cases.

Adopting a two-stage methodology inspired by de Ona et al. (2016), we initiate our analysis by clustering counties through K-means clustering based on their socioeconomic and demographic profiles, from which we are able to identify four distinct clusters. Subsequently, we construct regression trees for each cluster to examine the relationship between death rates and health-related factors. The finding underlines the significance of physical inactivity, although exceptions are noted in rural areas with high poverty and low education, where factors such as lack of insurance, and excessive drinking and heavy smoking are deemed crucial. These insights are valuable to policymakers to help make better informed decisions in cotaining virus spread and reduce COVID caused deaths.

Howeverm, given the amount of missing values in the data and unavailability of direct use of these entries, our analysis is conducted on the basis of `r nrow(cases_f)` counties out of `r nrow(cases)`. We acknowledge that there could exist undiscovered patterns if we had access to those values and this also has effect on the construction of the regression trees. Secondly, the determination of the number of clusters in our analysis is based on the elbow rule. However, this method has limitations, especially given the turning point is not exactly clear in our case study. Alternative evaluation metrics, such as information criteria and Jaccard coefficient, could be used to make a more comprehensive approach to optimize the clusters. Thirdly, we have to point that the trees are not stable -- a small variation in the data could result in a different tree. Alternative ensemble and boosting methods could be utilized to enhance the accuracy and stability but at the cost of the loss of easy interpretability of trees.

## References

de Ona, J., de Ona, R., Lopez, G. (2016). Transit service quality analysis using cluster analysis and decision trees: a step forward to personalized marketing in public transportation. Transportation, 43:725–747.

## Annex

### Links

Github: <https://github.com/wuyuntong/Group_Project>

Data Source:

Health data (2021 CHR CSV Analytic Data): <https://www.countyhealthrankings.org/explore-health-rankings/rankings-data-documentation>

COVID data (cases & deaths): <https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/>

Social-economic data (poverty, unemployment, education, & population): <https://www.ers.usda.gov/data-products/county-level-data-sets/county-level-data-sets-download-data/>

### Details on data pre-processing

For COVID cases and deaths datasets, we formatted the county FIPS code such that it is a 5-digit string. The FIPS for statewide unallocated cases and deathes is assigned a new value "99999". Variables important to the study(countyFIPS, County Name, State, StateFIPS and the numbers at the end of each month from Jul 2020 to June 2021) are reserved. After that, the case and death numbers are renamed corresponding to each month. A new row for US representing the nationwide cases and deaths is added.

For social-economic datasets, we keep only the countyFIPS and variables mentioned in the section of variable description. For health dataset, we merged county FIPS and state FIPS such that the FIPS code is line with other datasets. The variables for study are selected and are changed from the string type to numeric. Almost all the columns are complete, with no missing values.

For each one of cases and deaths, we join them by the primary key countyFIPS with the rest of the pre-processed datasets. Missing values are deleted. The resulting final ones are cases_f and deaths_f. These two datasets are used for clustering and regression tasks.
